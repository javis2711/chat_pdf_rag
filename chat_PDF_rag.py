import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os
import tempfile
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

api_key = os.getenv("GOOGLE_API_KEY")

if not api_key:
    st.error("Kh√¥ng t√¨m th·∫•y Key")
    st.stop()
    
genai.configure(api_key= api_key)

# Helper Functions
def get_PDF_text(pdf_docs):
    text = ""
    try:
        # T·∫°o ra 1 file copy ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin m√† kh√¥ng d√πng tr√™n file g·ªëc
        for pdf in pdf_docs: 
            with tempfile.NamedTemporaryFile(delete= False, suffix= ".pdf") as tmp_files:
                tmp_files.write(pdf.read())
                tmp_file_path = tmp_files.name
            
            pdf_reader = PyPDFLoader(tmp_file_path)
            # L·∫∑p qua t·ª´ng trang v√† l·∫•y th√¥ng tin
            for page in pdf_reader.load_and_split():
                text += page.page_content
            os.unlink(tmp_file_path) # X√≥a file t·∫°m
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc file PDF: {str(e)}")
    return text

def get_text_chunk(text):
    try:
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=1000)
        chunks = text_splitter.split_text(text)
        return chunks
    except Exception as e:
        st.error(f"L·ªói chia chunk: {str(e)}")
        return []
    
def get_vector_store(text_chunks):
    try:
        embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vector_store = FAISS.from_texts(text_chunks, embedding)
        vector_store.save_local("faiss_index")
        st.success("T√†i li·ªáu ƒë√£ ƒë∆∞·ª£c ph√¢n t√≠ch xong, ƒë√£ s·∫≥n s√†n ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi")
    except Exception as e:
        st.error(f"L·ªói l∆∞u vector database: {str(e)}")        
        return None
    
def get_conversational_chain():
    prompt_template = """
    Tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch chi ti·∫øt nh·∫•t c√≥ th·ªÉ d·ª±a tr√™n ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p. N·∫øu c√¢u tr·∫£ l·ªùi kh√¥ng c√≥ trong ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p, h√£y n√≥i, "C√¢u tr·∫£ l·ªùi kh√¥ng c√≥ trong ng·ªØ c·∫£nh."
    Kh√¥ng cung c·∫•p th√¥ng tin sai l·ªách.

    Ng·ªØ c·∫£nh: {context}
    C√¢u h·ªèi: {question}

    Answer:
    """
    try:
        model = ChatGoogleGenerativeAI(model ="gemini-2.0-flash", temperature=0.3)
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        chain = load_qa_chain(model, chain_type="stuff", prompt = prompt)
        return chain
    except Exception as e:
        st.error(f"L·ªói trong qu√° tr√¨nh ph√¢n t√≠ch {str(e)}")

def user_input(user_question):
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        if not os.path.exists("faiss_index"):
            st.error("Kh√¥ng t√¨m th·∫•y FAISS index. H√£y t·∫£i t√†i li·ªáu PDF l√™n tr∆∞·ªõc.")
            return
        new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
        docs = new_db.similarity_search(user_question)
        chain = get_conversational_chain()
        
        if not chain:
            return
        
        response = chain(
            {"input_documents": docs, "question": user_question},
            return_only_outputs=True
        )
        st.write("Reply: ", response["output_text"])
    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}")
        
# Setup trang ch√≠nh streamlit
st.set_page_config(page_title= "Chat PDG RAG", page_icon="ü•∏", layout= "wide")
st.title("Chatbot Ph√¢n t√≠ch t√†i li·ªáu PDF")

user_question = st.text_input("B·∫°n h√£y h·ªèi say khi t√†i li·ªáu ƒë√£ ƒë∆∞·ª£c ph√¢n t√≠ch xong")

if user_question:
    user_input(user_question)
    
with st.sidebar:
    st.title("Menu")
    pdf_docs = st.file_uploader("T·∫£i t√†i li·ªáu pdf c·ªßa b·∫°n l√™n", accept_multiple_files= True, type=["pdf"])
    
    if st.button("ph√¢n t√≠ch t√†i li·ªáu"):
        if not pdf_docs:
            st.error("Vui l√≤ng t·∫£i t√†i li·ªáu l√™n tr∆∞·ªõc")
        with st.spinner("ƒêang x·ª≠ l√Ω ...."):
            raw_text = get_PDF_text(pdf_docs)
            if raw_text:
                text_chunks = get_text_chunk(raw_text)
                if text_chunks:
                    get_vector_store(text_chunks)
                else:
                    st.error("Ki·ªÉm tra l·∫°i n·ªôi dung t√†i li·ªáu PDF")
